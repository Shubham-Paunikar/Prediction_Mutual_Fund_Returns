{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial Number  total_net_assets  net_annual_expenses_ratio  \\\n",
      "0           3935         284820000                       1.55   \n",
      "1          13836          71810000                       1.45   \n",
      "2           8956        6880000000                       0.94   \n",
      "3           9142         399430000                       1.00   \n",
      "4           5796         656280000                       2.69   \n",
      "\n",
      "   morningstar_rating  portfolio_cash  portfolio_stocks  portfolio_bonds  \\\n",
      "0                   3            6.97             14.80            77.25   \n",
      "1                   2           10.84             29.59            58.51   \n",
      "2                   4            0.78             99.22             0.00   \n",
      "3                   2            0.51             99.49             0.00   \n",
      "4                   4            7.78             23.60            68.49   \n",
      "\n",
      "   portfolio_others  portfolio_preferred  portfolio_convertable  ...  \\\n",
      "0              0.97                 0.00                   0.00  ...   \n",
      "1              0.94                 0.01                   0.01  ...   \n",
      "2              0.00                 0.00                   0.00  ...   \n",
      "3              0.00                 0.00                   0.00  ...   \n",
      "4              0.11                 0.00                   0.02  ...   \n",
      "\n",
      "   category_102  category_103  category_104  category_105  category_106  \\\n",
      "0           0.0           0.0           0.0           0.0           0.0   \n",
      "1           0.0           0.0           0.0           0.0           0.0   \n",
      "2           0.0           0.0           0.0           0.0           0.0   \n",
      "3           0.0           0.0           0.0           0.0           0.0   \n",
      "4           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "   category_107  investment_0  investment_1  investment_2  bonds_aaa  \n",
      "0           0.0           0.0           0.0           1.0       0.00  \n",
      "1           0.0           1.0           0.0           0.0      62.54  \n",
      "2           0.0           1.0           0.0           0.0       0.00  \n",
      "3           0.0           1.0           0.0           0.0       0.00  \n",
      "4           0.0           0.0           1.0           0.0       0.00  \n",
      "\n",
      "[5 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "data = pd.read_csv(\"Data.csv\")\n",
    "print(data.head())\n",
    "data.shape\n",
    "data.describe\n",
    "data = data.drop('Serial Number',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_net_assets</th>\n",
       "      <th>net_annual_expenses_ratio</th>\n",
       "      <th>portfolio_cash</th>\n",
       "      <th>portfolio_bonds</th>\n",
       "      <th>portfolio_others</th>\n",
       "      <th>portfolio_preferred</th>\n",
       "      <th>portfolio_convertable</th>\n",
       "      <th>sectors_basic_materials</th>\n",
       "      <th>sectors_consumer_cyclical</th>\n",
       "      <th>sectors_financial_services</th>\n",
       "      <th>...</th>\n",
       "      <th>category_102</th>\n",
       "      <th>category_103</th>\n",
       "      <th>category_104</th>\n",
       "      <th>category_105</th>\n",
       "      <th>category_106</th>\n",
       "      <th>category_107</th>\n",
       "      <th>investment_0</th>\n",
       "      <th>investment_1</th>\n",
       "      <th>investment_2</th>\n",
       "      <th>bonds_aaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284820000</td>\n",
       "      <td>1.55</td>\n",
       "      <td>6.97</td>\n",
       "      <td>77.25</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71810000</td>\n",
       "      <td>1.45</td>\n",
       "      <td>10.84</td>\n",
       "      <td>58.51</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.07</td>\n",
       "      <td>15.33</td>\n",
       "      <td>16.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6880000000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.96</td>\n",
       "      <td>10.35</td>\n",
       "      <td>28.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399430000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.61</td>\n",
       "      <td>27.77</td>\n",
       "      <td>10.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656280000</td>\n",
       "      <td>2.69</td>\n",
       "      <td>7.78</td>\n",
       "      <td>68.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>611090000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.80</td>\n",
       "      <td>60.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.21</td>\n",
       "      <td>12.60</td>\n",
       "      <td>10.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4640000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3.12</td>\n",
       "      <td>96.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70080000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.62</td>\n",
       "      <td>11.55</td>\n",
       "      <td>21.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1050000000</td>\n",
       "      <td>0.43</td>\n",
       "      <td>15.45</td>\n",
       "      <td>80.83</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125150000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.79</td>\n",
       "      <td>99.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_net_assets  net_annual_expenses_ratio  portfolio_cash  \\\n",
       "0         284820000                       1.55            6.97   \n",
       "1          71810000                       1.45           10.84   \n",
       "2        6880000000                       0.94            0.78   \n",
       "3         399430000                       1.00            0.51   \n",
       "4         656280000                       2.69            7.78   \n",
       "5         611090000                       0.83            1.80   \n",
       "6        4640000000                       0.98            3.12   \n",
       "7          70080000                       0.89            4.16   \n",
       "8        1050000000                       0.43           15.45   \n",
       "9         125150000                       0.55            0.79   \n",
       "\n",
       "   portfolio_bonds  portfolio_others  portfolio_preferred  \\\n",
       "0            77.25              0.97                 0.00   \n",
       "1            58.51              0.94                 0.01   \n",
       "2             0.00              0.00                 0.00   \n",
       "3             0.00              0.00                 0.00   \n",
       "4            68.49              0.11                 0.00   \n",
       "5            60.23              0.03                 0.00   \n",
       "6            96.56              0.32                 0.00   \n",
       "7             0.00              0.00                 0.00   \n",
       "8            80.83              1.58                 0.00   \n",
       "9            99.21              0.00                 0.00   \n",
       "\n",
       "   portfolio_convertable  sectors_basic_materials  sectors_consumer_cyclical  \\\n",
       "0                   0.00                     0.00                       0.00   \n",
       "1                   0.01                     7.07                      15.33   \n",
       "2                   0.00                     4.96                      10.35   \n",
       "3                   0.00                     5.61                      27.77   \n",
       "4                   0.02                     0.00                       0.00   \n",
       "5                   0.00                     3.21                      12.60   \n",
       "6                   0.00                     0.00                       0.00   \n",
       "7                   0.00                     6.62                      11.55   \n",
       "8                   0.00                     0.00                       0.00   \n",
       "9                   0.00                     0.00                       0.00   \n",
       "\n",
       "   sectors_financial_services  ...  category_102  category_103  category_104  \\\n",
       "0                        0.00  ...           0.0           0.0           0.0   \n",
       "1                       16.54  ...           0.0           0.0           0.0   \n",
       "2                       28.78  ...           0.0           0.0           0.0   \n",
       "3                       10.69  ...           0.0           0.0           0.0   \n",
       "4                        0.00  ...           0.0           0.0           0.0   \n",
       "5                       10.25  ...           0.0           0.0           0.0   \n",
       "6                        0.00  ...           0.0           0.0           0.0   \n",
       "7                       21.21  ...           0.0           0.0           0.0   \n",
       "8                        0.00  ...           0.0           0.0           0.0   \n",
       "9                        0.00  ...           0.0           0.0           0.0   \n",
       "\n",
       "   category_105  category_106  category_107  investment_0  investment_1  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           1.0           0.0   \n",
       "2           0.0           0.0           0.0           1.0           0.0   \n",
       "3           0.0           0.0           0.0           1.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           1.0   \n",
       "5           0.0           0.0           0.0           0.0           1.0   \n",
       "6           0.0           0.0           0.0           0.0           0.0   \n",
       "7           0.0           0.0           0.0           0.0           0.0   \n",
       "8           0.0           0.0           0.0           1.0           0.0   \n",
       "9           0.0           0.0           0.0           1.0           0.0   \n",
       "\n",
       "   investment_2  bonds_aaa  \n",
       "0           1.0       0.00  \n",
       "1           0.0      62.54  \n",
       "2           0.0       0.00  \n",
       "3           0.0       0.00  \n",
       "4           0.0       0.00  \n",
       "5           0.0      77.01  \n",
       "6           1.0      11.28  \n",
       "7           1.0       0.00  \n",
       "8           0.0       0.00  \n",
       "9           0.0     100.00  \n",
       "\n",
       "[10 rows x 148 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   return  risk\n",
      "3    3892  3845\n",
      "4    2628  2614\n",
      "2    2422  2218\n",
      "0    1236  1236\n",
      "5     956  1080\n",
      "1     764   905\n",
      "Dependent (reject H0)\n",
      "significance=0.050, p=0.000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------\n",
    "#Importing header files\n",
    "from scipy.stats import chi2_contingency\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Critical value \n",
    "critical_value = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 11)   # Df = number of variable categories(in purpose) - 1\n",
    "\n",
    "# Code starts here\n",
    "prob = 0.95\n",
    "return_rating = data[\"morningstar_return_rating\"].value_counts()\n",
    "risk_rating = data[\"morningstar_risk_rating\"].value_counts()\n",
    "observed = pd.concat([return_rating.transpose() ,risk_rating.transpose()] , axis=1 , keys= ['return','risk'])\n",
    "print(observed)\n",
    "\n",
    "chi2 , p, dof, ex = chi2_contingency(observed)\n",
    "if abs(chi2) >= critical_value:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "\n",
    "\n",
    "# Code ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['morningstar_rating'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1264d0cc524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# data = data.drop(np.unique(max_correlated.index.get_level_values(0)), 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#print(data[max_correlated.index])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'morningstar_rating'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'portfolio_stocks'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category_12'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['morningstar_rating'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------\n",
    "# Code starts here\n",
    "correlation = abs(data.corr())\n",
    "#print(correlation)\n",
    "us_correlation = correlation.unstack()\n",
    "#us_correlation = pd.DataFrame(us_correlation)\n",
    "us_correlation = us_correlation.sort_values(ascending = False)\n",
    "max_correlated = us_correlation[(us_correlation>0.75) & (us_correlation<1)]\n",
    "# print(max_correlated, np.unique(max_correlated.index.get_level_values(0)))\n",
    "# data = data.drop(np.unique(max_correlated.index.get_level_values(0)), 1)\n",
    "#print(data[max_correlated.index])\n",
    "data.drop('morningstar_rating',1, inplace=True)\n",
    "data.drop('portfolio_stocks',1, inplace=True)\n",
    "data.drop('category_12',1, inplace=True)\n",
    "# data.drop('morningstar_return_rating',1)\n",
    "# data.drop('sharpe_ratio_3y',1)\n",
    "# data.drop('sharpe_ratio_3y',1)\n",
    "data.drop('sharpe_ratio_3y',1, inplace=True)\n",
    "# data.drop('sharpe_ratio_3y',1)\n",
    "# code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'net_annual_expenses_ratio')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+cVPV97/HXG4RFjYLgJvEXQrxqVlZK41bTuk3cRECNF9Le2yqmVus2ZCHZtCW5Ibh9XLXtamyTa1MS2UKWoLdxY2oSw031Aoa9tWsTU0wMgqv1FyqG6CqKFiug+dw/zlkyrPt7Zvbs7Lyfj8c8Zs73/JjPzPmez3zne34pIjAzs/IwLusAzMxs5Djpm5mVESd9M7My4qRvZlZGnPTNzMqIk76ZWRlx0i8ASb8t6dGs4ygESVdL+lrWcVjpkHSepJ1ZxzHWSfqYpI15L8fH6ZtlS9IO4I8j4p6sYxkOSecB/xARJ2Ydy1ghaQbwFDAhIt4s5LLd0s+TpMOyjmGwSilWs7FM0vis3ttJvw+SdkhaIelhSS9L+rqkSd1/ZSUtl/QL4Os9/95KOknSdyR1SXpJ0ldyxl0lqTNd5gZJJw8ilvdK2iRpt6RHJf1+zriPSPqppFclPSvp2pxxMySFpHpJzwCbc8qukPSMpBclNeXMc62kf+gxf1/THi7plvSzdEr6XDn/zU/rzGclbZW0R9Ltkial4y6W9KCkVyT9q6TZafn/BqYD/0fSf0j63ADv8Y+SfpEu/15Js3LGrZP0VUn/JOk1SfdLOiVnfEhqkPRYus6+KknpuIPrPR3uXveHpcN/lK7j1yQ9KekTw/h+jpf07XS7eErSp3PG3SXpSznDt0tam76+UtJ9klamn/sRSR/OmXaypFZJuyQ9J+mvupNqOm+HpC+mn/kpSRfmzHtl+nleS8d9LGdcr9uqEjdJeiGNZ6uk6gE++zpJq9LPuReo62/bBe5Nn19J68Vvdn+WnGX+lqR/S2P4N0m/NagVERF+9PIAdgDbgJOAqcB9wF8B5wFvAjcCFcDhadnOdL7xwM+Am4AjgUlAbTruo8DjQBVwGPDnwL8OEMeRwLPAH6XzvA94EZiVjj8POJPkB3w28Dzw0XTcDCCAW9PlHJ5TtiYd/jVgH1CVznMtyV91BjHtF4B/Bo4BTgS2dn8P5fhI68yPgePTOtMJNKTr7AXgnLR+XJFOW5Ez3/mDfI+rgKPSuve3wIM549YBu4Gz07ryDeCbOeMD+D4wheSHpgu4oOd677HuD0uHPwKcAgj4IPA68L6cOtjvek/r5wPA/wQmAu8BngTmp+PfnX5HHwI+lo47Kh13Jck292fABOASYA8wNR1/J/D3aR1/Z7oOPpEz7wHg4+l3vwT4efo5jgReBU5Ppz2OX21XfW6rwPz0s0xJl1MFHDfA51+Xxnxu+l1MYnDb7mE5y7gS6EhfTwVeBi5P41uUDk8bsA5lvaGM1gfJhtiQM3wR8ES6ovYDk3LGHaz0wG+SbEyH9bLMu4H6HhvC68DJ/cRxCfAvPcr+Hrimj+n/FripR8V5T8747rITc8p+DFyavr6Wtyf9vqY9uNGmw3+Mk/4f5Az/NdACrAL+sse0jwIfzJlvUEm/xzKmpOtncjq8Dvhajzr7SM5wkDZA0uFvAZ/vud57rPu31eN0/J3An6SvD9b/fmI9B3imR9kK4Os5w79L0sB5sUecV5Im6h718HLgXSQNkcNzxi0C2nPmfTxn3BHp53o3SdJ/BfhvufOn0/W5rZL8MP078H5g3CDX1Trg1gGm6W3b7SvpXw78uMf8PwSuHCgWd+/079mc10+TtOAAuiLijT7mOQl4Onrf+XIy8OX0L/4rJK0yASf0E8PJwDnd86TzfYyk0iLpHEnt6V/mPSQty2P7+RzdfpHz+nXgHf3E0Ne0x/dYdm/vU256+65OBj7TYx2exK/q06BIGi/pC5KekPQqyY8FHLq+B1qvQ1nvue99oaQfKelifIXkB6VnPevPycDxPb6Dq0mSdrfvk7TGH42Ijh7zPxdpZkt1b48nk7T+d+Us9+9JWvzdDn7miHg9ffmOiNhL0qhqSOf/J0nvzYm31201IjYDXwG+CjwvabWkowfxHRyyfQxy2+3L8el3kOtp+s8lgPv0B3JSzuvpJK0NSH6B+/IsMF297zR9luRv55Scx+ER8a8DLO+fe8zzjohYko6/DVgPnBQRk0laluqxjGIdorWLpFun20l9TVjmngWae6zDIyKiLR0/2PVzGbAQOB+YTNIahLev7+HYS9IK7vbu7heSKoBvA18E3hURU4C7hvi+zwJP9fgOjoqIi3KmaSbpEjtO0qIe85/Qvf8h1b09PkvS0j82Z7lHR8QsBiEiNkTEXJKunUdIujK74+1zW42Iv4uIs4BZwGnA/xjM2/UY7m/bHahO/JzkhynXdOC5gYJw0u/fJyWdKGkqSavk9kHM82OSZPgFSUcq2fl7bjquBVihdOdbugPq9wZY3veB0yRdLmlC+vgNSVXp+KOA3RHxhqSzSRLDSPkWyec5RtIJwKdG8L1LyRqgIW3ZKa0XH5F0VDr+eZI+7oEcRZLgXiJJ0NcXMMYHgQ9Imi5pMknXS7eJJPsQuoA30x2h84a4/B8Dryo5AOLw9F9LtaTfAJD0AZL9Vn+YPlamdarbO4FPp/X/90j60e+KiF3ARuBLko6WNE7SKZI+OFBAkt4laYGkI0m+1/8A3kpH97mtptvfOZImkPxYvpEz31D0t+12Ab+k73pxF0leuEzSYZIuAc4gyRf9ctLv320kFerJ9PFXA80QEW8B/xX4L8AzwE6Sv5BExHdJdgB/M/17vg24sI9FdS/vNZIN7FKSX/df8KudyABLgb+Q9BrJTrJvDekT5ucvSD7fU8A9wB0kG4/liIgtJDsSv0Kys+1xkv7ZbjcAf552JXy2n0XdSvIX/jngYeBHBYxxE0mjZivJTsrv54x7Dfg0Sd16mSQ5rR/i8ru3izkk9eVF4GvA5LRr5FbgUxHxXNq100pyZFx3y/d+4NR0vmbgv0fES+m4PyT5YXo4je8Okpb7QMYBnyHZrnaT7KBemsbb37Z6NMkP+csk6+Mlkn9BQ9Xntpt2QzUD96X14v25M6af/eI0/peAzwEXR8SLA72pT87qg0r8hJksSFpCspN3wFaW2WBJupJkW6zNOpaxwC19GzZJx0k6N/1LfTpJq+O7WcdlZn1z0h8FlFy75z96e2Qd2wAmkhwp8RqwGfgecHOmEZU4JddX6a0ubM86toGk+wN6rceSpmcdX7FJ2t7HZ//YwHOPHHfvmJmVEbf0zczKyKi4ANexxx4bM2bMyDoMG8MeeOCBFyOicqTf13Xbimk49XpUJP0ZM2awZcuWrMOwMUxSz7MXR4TrthXTcOq1u3fMzMqIk76ZWRlx0jczKyNO+mZmZcRJ38ysjDjpl5DZs2cj6eBj9uzZWYdkVhBtbW1UV1czfvx4qquraWtrG3gmGxYn/RIxe/ZsHnroIRYsWEBXVxcLFizgoYcecuK3ktfW1kZTUxMrV67kjTfeYOXKlTQ1NTnxF8tgbvVV7MdZZ50V1j8gFixYcEjZggULIlmFNhBgS7huj0qzZs2KzZs3H1K2efPmmDVrVkYRlY7h1OtRce2dmpqa8Aks/ZNEV1cXxx77q7upvfjii1RWVjIa1uFoJ+mBiKgZ6fd13R7Y+PHjeeONN5gwYcLBsgMHDjBp0iTeems49yYpH8Op1wN270haK+kFSdtyym6X9GD62CHpwbR8hqT/zBnXMvSPYX2pr6/vd9isFFVVVdHRcegtcTs6OqiqqupjDsvHYPr01wEX5BZExCURMSci5pDcO/M7OaOf6B4XEQ2FC7W8nXnmmaxfv56FCxfy4osvsnDhQtavX8+ZZ56ZdWhmeWlqaqK+vp729nYOHDhAe3s79fX1NDU1ZR3amDTgtXci4l5JM3obl97K7PeBDxU2LOtp69atzJ49m/Xr11NZmVxf6cwzz2Tr1q0ZR2aWn0WLknugNzY20tnZSVVVFc3NzQfLrbDyveDabwPPR8RjOWUzJf0UeBX484j4l95mlLQYWAwwffqYv79CQTjBjwxJa0nuP/pCRFT3GPdZ4G+AyhjE/UhtcBYtWuQkP0LyPWRzEZB7XNUuYHpE/DqwDLgtvenx20TE6oioiYia7par2Sixjh5dmgCSTgLmktzw3qwkDTvpSzoM+F3g9u6yiNgX6R3qI+IB4AngtHyDNBtJEXEvsLuXUTcBnwN8uJSVrHxa+ucDj0TEzu4CSZWSxqev3wOcCjyZX4hm2ZO0AHguIn42iGkXS9oiaUtXV9cIRGc2eIM5ZLMN+CFwuqSdkrqPE7yUQ7t2AD4AbJX0M+AOoCEiemsxmZUMSUcATcD/HMz07rq00WwwR+/0unclIq7spezbJIdwmo0lpwAzgZ8lB6xxIvATSWdHxC8yjcxsiEbF7RLNRrOIeAh4Z/ewpB1AjY/esVLkC66Z9dBPl6ZZyXNL36yHvro0c8bPGKFQzArOLX0zszLipG9mVkac9M3MyoiTvplZGXHSNzMrI076ZmZlxEnfzKyMOOmbmZURJ30zszLipG9mVkac9EtIW1sb1dXVjB8/nurqatrael7Z2sysf772Toloa2ujqamJ1tZWamtr6ejooL4+uQ6Y7y1qZoPlln6JaG5uprW1lbq6OiZMmEBdXR2tra00NzdnHZqZlRAn/RLR2dlJbW3tIWW1tbV0dnZmFJGZlSIn/RJRVVVFR0fHIWUdHR1UVVVlFJGZlaLB3CN3raQXJG3LKbtW0nOSHkwfF+WMWyHpcUmPSppfrMDLTVNTE/X19bS3t3PgwAHa29upr6+nqakp69DMrIQMZkfuOuArwK09ym+KiC/mFkg6g+SG6bOA44F7JJ0WEW8VINay1r2ztrGxkc7OTqqqqmhubvZOXDMbksHcGP1eSTMGubyFwDcjYh/wlKTHgbNJbj1neVq0aJGTvJnlJZ8+/U9J2pp2/xyTlp0APJszzc60zMzMRoHhJv1VwCnAHGAX8KW0XL1MG70tQNJiSVskbenq6hpmGGaF18d+rL+R9Eja0PmupClZxmg2XMNK+hHxfES8FRG/BNaQdOFA0rI/KWfSE4Gf97GM1RFRExE1lZWVwwnDrFjWARf0KNsEVEfEbODfgRUjHZRZIQwr6Us6Lmfwd4DuFtF64FJJFZJmAqcCP84vRLORFRH3Art7lG2MiDfTwR+RNGjMSs6AO3IltQHnAcdK2glcA5wnaQ5J180O4BMAEbFd0reAh4E3gU/6yB0bg64Cbu9rpKTFwGKA6dOnj1RMZoMymKN3ejtcpLWf6ZsBXxvAxiRJTSQNmm/0NU1ErAZWA9TU1PS6T8ssK77gmtkgSboCuBj4cEQ4mVtJctI3GwRJFwDLgQ9GxOtZx2M2XL72jlkP6X6sHwKnS9opqZ7krPSjgE3ppUdaMg3SbJjc0jfrYaj7scxKiVv6ZmZlxEnfzKyMOOmbmZURJ30zszLipG9mVkac9M3MyoiTvplZGXHSNzMrI076ZmZlxEnfzKyMOOmbmZURJ30zszLipG9mVkac9M3MyoiTvplZGRkw6UtaK+kFSdtyyv5G0iOStkr6rqQpafkMSf+Z3mTCN5owMxtlBtPSXwdc0KNsE1AdEbOBfwdW5Ix7IiLmpI+GwoRpZmaFMGDSj4h7gd09yjZGxJvp4I+AE4sQm5mZFVgh+vSvAu7OGZ4p6aeS/lnSb/c1k6TFkrZI2tLV1VWAMMwKo48uzamSNkl6LH0+JssYzYYrr6QvqQl4E/hGWrQLmB4Rvw4sA26TdHRv80bE6oioiYiaysrKfMIwK7R1vL1L8/PADyLiVOAH6bBZyRl20pd0BXAx8LGICICI2BcRL6WvHwCeAE4rRKBmI6W3Lk1gIXBL+voW4KMjGpRZgQwr6Uu6AFgOLIiI13PKKyWNT1+/BzgVeLIQgZpl7F0RsQsgfX5nXxO669JGs8EcstkG/BA4XdJOSfXAV4CjgE09Ds38ALBV0s+AO4CGiOjZYjIb09x1aaPZYQNNEBGLeilu7WPabwPfzjcos1HoeUnHRcQuSccBL2QdkNlw+Ixcs8FZD1yRvr4C+F6GsZgNm5O+WQ99dGl+AZgr6TFgbjpsVnIG7N4xKzd9dGkCfHhEAzErArf0S0hbWxvV1dWMHz+e6upq2trasg7JzEqMW/oloq2tjaamJlpbW6mtraWjo4P6+noAFi3qq2FqZnYot/RLRHNzM62trdTV1TFhwgTq6upobW2lubk569DMrIQ46ZeIzs5OamtrDymrra2ls7Mzo4jMrBQ56ZeIqqoqOjo6Dinr6Oigqqoqo4jMrBQ56ZeIpqYm6uvraW9v58CBA7S3t1NfX09TU1PWoZlZCfGO3BLRvbO2sbGRzs5OqqqqaG5u9k5cMxsSJ/0SsmjRIid5M8uLu3dKyLRp05B08DFt2rSsQzKzEuOkXyKmTZvG7t27mTVrFk8//TSzZs1i9+7dTvxmNiTu3ikR3Ql/27bkDn7btm2jurqa7du3ZxyZmZUSt/RLyF133dXvsJnZQJz0S8hFF13U77CZ2UCc9EvE1KlT2b59O9XV1TzzzDMHu3amTp2adWhmVkLcp18iXnrpJaZNm8b27ds5+eSTgeSH4KWXXso4MjMrJU76JcQJ3szyNajuHUlrJb0gaVtO2VRJmyQ9lj4fk5ZL0t9JelzSVknvK1bwZmY2NIPt018HXNCj7PPADyLiVOAH6TDAhcCp6WMxsCr/MM3MrBAGlfQj4l5gd4/ihcAt6etbgI/mlN8aiR8BUyQdV4hgzbIm6c8kbZe0TVKbpElZx2Q2FPkcvfOuiNgFkD6/My0/AXg2Z7qdadkhJC2WtEXSlq6urjzCMBsZkk4APg3UREQ1MB64NNuozIamGIdsqpeyeFtBxOqIqImImsrKyiKEYVYUhwGHSzoMOAL4ecbxmA1JPkn/+e5um/T5hbR8J3BSznQn4g3DxoCIeA74IvAMsAvYExEbe07nf7E2muWT9NcDV6SvrwC+l1P+h+lRPO8n2TB25fE+lpo/fz7jxo1DEuPGjWP+/PlZh1RW0iPUFgIzgeOBIyX9Qc/p/C/WRrPBHrLZBvwQOF3STkn1wBeAuZIeA+amwwB3AU8CjwNrgKUFj7oMzZ8/n40bN9LQ0MArr7xCQ0MDGzdudOIfWecDT0VEV0QcAL4D/FbGMZkNyaBOzoqIvu7c8eFepg3gk/kEZW+3adMmlixZws033wxw8LmlpSXLsMrNM8D7JR0B/CdJ/d+SbUhmQ+Nr75SIiOCGG244pOyGG24g+Y21kRAR9wN3AD8BHiLZflZnGpTZEDnplwhJrFix4pCyFStWIPV2sJQVS0RcExHvjYjqiLg8IvZlHZPZUDjpl4i5c+eyatUqli5dyp49e1i6dCmrVq1i7ty5WYdmZiXEF1wrERs2bGD+/Pm0tLSwatUqJDFv3jw2bNiQdWhmVkKc9EuIE7yZ5cvdO2ZmZcRJ38wy19jYyKRJk5DEpEmTaGxszDqkMctJ38wy1djYSEtLC9dffz179+7l+uuvp6WlxYm/SJz0zSxTa9as4cYbb2TZsmUcccQRLFu2jBtvvJE1a9ZkHdqY5KRvZpnat28fDQ0Nh5Q1NDSwb59PgSgGJ30zy1RFRcXbLifS0tJCRUVFRhGNbT5k08wy9fGPf5zly5cDSQu/paWF5cuXv631b4XhpG9mmVq5ciUAV199NZ/5zGeoqKigoaHhYLkVlpO+mWVu5cqVTvIjxH36ZmZlxEnfzDLX1tZGdXU148ePp7q6mra2tqxDGrPcvWNmmWpra6OpqYnW1lZqa2vp6Oigvr4egEWL+rp/kw2XW/pmlqnm5mZaW1upq6tjwoQJ1NXV0draSnNzc9ahjUlO+iXEN0a3saizs5Pa2tpDympra+ns7MwoorFt2Elf0umSHsx5vCrpTyVdK+m5nPKLChlwufKN0W2sqqqq4rrrrjukT/+6666jqqoq69DGpGEn/Yh4NCLmRMQc4CzgdeC76eibusdFxF2FCLTc5d4YffLkydx8880sWbKETZs2ZR1aWZE0RdIdkh6R1CnpN7OOqdTV1dVx4403ctVVV/Haa69x1VVXceONN1JXV5d1aGNSobp3Pgw8ERFPF2h51oNvjD5qfBn4vxHxXuDXAPdB5Km9vZ3ly5ezdu1ajjrqKNauXcvy5ctpb2/POrQxqVBJ/1Ig9xirT0naKmmtpGN6m0HSYklbJG3p6uoqUBhjl2+Mnj1JRwMfAFoBImJ/RLySbVSlr7Ozk2uuuYZt27bx1ltvsW3bNq655hr36RdJ3klf0kRgAfCPadEq4BRgDrAL+FJv80XE6oioiYiaysrKfMMY83xj9FHhPUAX8HVJP5X0NUlH9pzIDZqhqaqqoqOj45Cyjo4O9+kXS0Tk9QAWAhv7GDcD2DbQMs4666ywgc2bNy8kBRCSYt68eVmHVDKALZF/Xa8B3gTOSYe/DPxlf/O4bg/stttui5kzZ8bmzZtj//79sXnz5pg5c2bcdtttWYc26g2nXhfi5KxF5HTtSDouInalg78DbCvAexi+MfoosBPYGRH3p8N3AJ/PMJ4xofsErMbGRjo7O6mqqqK5udknZhVJXklf0hHAXOATOcV/LWkOEMCOHuPMSlZE/ELSs5JOj4hHSQ5geDjruMyGIq+kHxGvA9N6lF2eV0Rmo1sj8I10X9aTwB9lHE/J82UYRpbPyDUbgoh4MJIDEGZHxEcj4uWsYyp1vgzDyHLSN7NM+TIMI8tJ38wy5UM2R5aTvpllqqmpifr6etrb2zlw4ADt7e3U19fT1NSUdWhjkq+nb2aZ8iGbI8stfTOzMuKWvpllyodsjiy39M0sU83NzVx22WU0NjYyadIkGhsbueyyy3zIZpG4pW9mmXr44YfZu3cva9euPdjSv+qqq3j6aV+pvRic9M0sUxMnTuTcc889ZEfuueeey65duwae2YbM3Ttmlql9+/Zx++23H3LnrNtvv519+/ZlHdqY5KRvZpmqqKjgnHPO4eqrr+bII4/k6quv5pxzzqGioiLr0MYkJ30zy9S+ffu4//77uf7669m7dy/XX389999/v1v6ReKkb2aZqqio4JJLLjnkHrmXXHKJW/pF4qRvZpnav38/9913HytXruSNN95g5cqV3Hfffezfvz/r0MYkJ/0SMn/+fMaNG4ckxo0bx/z587MOySxvZ5xxBnPmzOHCCy9k4sSJXHjhhcyZM4czzjgj69DGJCf9EjF//nw2btxIQ0MDr7zyCg0NDWzcuNGJ30peXV0d69evZ8qUKQBMmTKF9evXU1dXl3FkY5OTfonYtGkTS5Ys4eabb2by5MncfPPNLFmyhE2bNmUdmlle7rzzTioqKti9ezcAu3fvpqKigjvvvDPjyMamvJO+pB2SHpL0oKQtadlUSZskPZY+H5N/qOUtIrjhhhsOKbvhhhuIiIwiMiuMnTt3MnnyZDZs2MD+/fvZsGEDkydPZufOnVmHNiYVqqVfFxFzIqImHf488IOIOBX4QTpseZDEihUrDilbsWIFkjKKqHxJGi/pp5K+n3UsY8WyZcsOuV3ismXLsg5pzCpW985C4Jb09S3AR4v0PmVj7ty5rFq1iqVLl7Jnzx6WLl3KqlWrmDt3btahlaM/AXwvvwJqbm5m5syZjBs3jpkzZ/pia0VUiKQfwEZJD0hanJa9KyJ2AaTP7+w5k6TFkrZI2tLV1VWAMMa2DRs2MG/ePFpaWpgyZQotLS3MmzePDRs2ZB1aWZF0IvAR4GtZxzJWTJ06lT179rBjxw4igh07drBnzx6mTp2adWhjUiGS/rkR8T7gQuCTkj4wmJkiYnVE1ERETWVlZQHCGPtOO+00Jk6cCCQXqTrttNMyjqgs/S3wOeCXfU3gBs3Q9HXmrc/ILY68k35E/Dx9fgH4LnA28Lyk4wDS5xfyfZ9y19jYSEtLyyGnqre0tNDY2Jh1aGVD0sXACxHxQH/TuUEzNHv37gVg3Lhxhzx3l1th5ZX0JR0p6aju18A8YBuwHrginewK4Hv5vI/BmjVrej1Vfc2aNVmHVk7OBRZI2gF8E/iQpH/INqSxoaKignvuuYf9+/dzzz33+BIMRaR8DvmT9B6S1j0k1+a/LSKaJU0DvgVMB54Bfi8idve1nJqamtiyZcuw4ygH/R2l48M2BybpgZyjywqxvPOAz0bExf1N57o9MNft4RtOvc7rJioR8STwa72UvwR8OJ9lm5lZ4fmM3BIzbtw47rnnnoP9npaNiPh/A7XyzUYjZ44SM2HCBM4//3wmTJiQdShmVoKc9EvM3Xffzf79+7n77ruzDsXMSpBvjD7K9dzJ9aEPfajfabzjy8z646Q/ynUncR/hYGaF4O6dEtFXYnfCN7OhcEu/hOS2+p3szWw43NI3MysjTvpmZmXESd/MrIw46ZuZlREnfTOzMuKkb2ZWRpz0zczKiJO+mVkZcdI3MysjPiPXzEZcf9eS6ms6n4VeGE76ZjbichO4LyY4sty9Y2ZWRoad9CWdJKldUqek7ZL+JC2/VtJzkh5MHxcVLlwzG2t8BdmRlU/3zpvAZyLiJ5KOAh6QtCkdd1NEfDH/8MxGD0knAbcC7wZ+CayOiC9nG9XY4CvIjpxhJ/2I2AXsSl+/JqkTOKFQgZmNQr02dCLi4awDMxusgvTpS5oB/Dpwf1r0KUlbJa2VdEwf8yyWtEXSlq6urkKEYVZUEbErIn6Svn4NcEPHSk7eSV/SO4BvA38aEa8Cq4BTgDkk/wS+1Nt8EbE6ImoioqaysjLfMMxGVC8NndxxbtDYqJVX0pc0gSThfyMivgMQEc9HxFsR8UtgDXB2/mGajR69NHQO4QaNjWb5HL0joBXojIj/lVN+XM5kvwNsG354ZqNLbw0ds1KSz9E75wKXAw9JejAtuxpYJGkOEMAO4BN5RWg2SvTV0DErJfkcvdMB9HYq3V3DD8dsVOu1oRMRrvNWMnwZBrNB6qehY1YyfBkGM7My4qRvZlZGnPRHialTpyJpUA9g0NNKYurUqRl/OisE16s6AAACuUlEQVRnxarbrtfD4z79UeLll18u2jVHBnvtcrNiKFbddr0eHif9USKuORqunVy8ZZuZ4aQ/aui6V4va0o9ri7JoMysx7tM3MysjTvpmZmXE3TtmVlTF2l/lfVXD46RvZkVVrP1V3lc1PO7eMTMrI076ZmZlxN07ZlZ0xTiR6phjer0Tqw3ASd/Mimoo/fmSina+iiXcvWNmVkac9M3MyoiTvplZGXHSNzMrI0VL+pIukPSopMclfb5Y72M2klyvrdQVJelLGg98FbgQOANYJOmMYryX2UhxvbaxoFgt/bOBxyPiyYjYD3wTWFik9zIbKa7XVvKKlfRPAJ7NGd6Zlh0kabGkLZK2dHV1FSmM0jKUWyAO5eGTWApmwHoNrtuDMZzbJVphFCvp97aGDjnjIiJWR0RNRNRUVlYWKYzSERFFe+zevTvrjzdWDFivwXV7MIZTj60wipX0dwIn5QyfCPy8SO9lNlJcr63kFSvp/xtwqqSZkiYClwLri/ReZiPF9dpKXlGuvRMRb0r6FLABGA+sjYjtxXgvs5Hiem1jQdEuuBYRdwF3FWv5ZllwvbZS5zNyzczKiJO+mVkZcdI3MysjTvpmZmVEo+GkB0ldwNNZx1FCjgVezDqIEnNyRIz4mVKu20Pmuj00Q67XoyLp29BI2hIRNVnHYVZortvF5+4dM7My4qRvZlZGnPRL0+qsAzArEtftInOfvplZGXFL38ysjDjpm5mVESf9EiJpraQXJG3LOhazQnLdHjlO+qVlHXBB1kGYFcE6XLdHhJN+CYmIewHf+9DGHNftkeOkb2ZWRpz0zczKiJO+mVkZcdI3MysjTvolRFIb8EPgdEk7JdVnHZNZIbhujxxfhsHMrIy4pW9mVkac9M3MyoiTvplZGXHSNzMrI076ZmZlxEnfzKyMOOmbmZWR/w/dgiMrTMcbHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------\n",
    "# Code starts here\n",
    "f, (ax_1, ax_2) = plt.subplots(1, 2)\n",
    "ax_1.boxplot(data['price_earning'])\n",
    "ax_1.set_title('price_earning')\n",
    "ax_2.boxplot(data[\"net_annual_expenses_ratio\"])\n",
    "ax_2.set_title('net_annual_expenses_ratio')\n",
    "\n",
    "# code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of model is: 16\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from math import sqrt\n",
    "# Code starts here\n",
    "X = data.drop('bonds_aaa',1)\n",
    "y = data['bonds_aaa'].copy()\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y, test_size = 0.3 , random_state = 3)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test,y_pred))\n",
    "print(\"The RMSE of model is:\",round(rmse))\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.75827e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.6933e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.86067e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.27231e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.07749e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.57876e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.05378e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.0149e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.11501e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.75481e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.69018e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.85683e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.24255e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.05006e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.54748e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.04233e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.00419e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.10274e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.70903e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.67703e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.76948e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.42397e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.31719e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.42599e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.34338e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.82349e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.50409e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.40587e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.26454e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.43024e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.01365e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.95868e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.51546e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.66447e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.36011e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.74779e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.53534e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 15.720131026226944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE: 15.719153628852961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda_Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------\n",
    "# import libraries\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# regularization parameters for grid search\n",
    "ridge_lambdas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60]\n",
    "lasso_lambdas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1]\n",
    "\n",
    "# Code starts here\n",
    "regressor = LinearRegression()\n",
    "ridge_model = Ridge(random_state = 0)\n",
    "ridge_grid = GridSearchCV(estimator=ridge_model, param_grid=dict(alpha=ridge_lambdas))\n",
    "ridge_grid.fit(X_train,y_train)\n",
    "ridge_pred = ridge_grid.predict(X_test)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(ridge_pred,y_test))\n",
    "print(\"Ridge RMSE:\",ridge_rmse)\n",
    "\n",
    "lasso_model = Lasso(random_state = 0)\n",
    "lasso_grid = GridSearchCV(estimator=lasso_model, param_grid=dict(alpha=lasso_lambdas))\n",
    "lasso_grid.fit(X_train,y_train)\n",
    "lasso_pred = lasso_grid.predict(X_test)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(lasso_pred,y_test))\n",
    "print(\"Lasso RMSE:\",lasso_rmse)\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
